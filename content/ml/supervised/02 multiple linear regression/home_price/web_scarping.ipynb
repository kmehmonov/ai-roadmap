{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb71ce8",
   "metadata": {},
   "source": [
    "### Web Scraping and building pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d410bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from home_classes import Home, HomeCollection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd5e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.olx.uz\"\n",
    "FILTERED_PAGES_BASE_URL = \"https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d49106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get htm content from url\n",
    "def get_html(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d6b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup from html content\n",
    "def create_soup(html_content):\n",
    "    if html_content:\n",
    "        return BeautifulSoup(html_content, 'html.parser')\n",
    "    else:\n",
    "        print(\"No HTML content to parse.\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f01ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of pages and page URLs\n",
    "def get_pages_urls_as_list(filtered_page_html_content):\n",
    "\n",
    "    soup = create_soup(filtered_page_html_content)\n",
    "    # Get pagination block\n",
    "    pagination = soup.find(\"ul\", class_=\"pagination-list\")\n",
    "\n",
    "    # Extract all valid <a> tags with numeric page text\n",
    "    page_links = pagination.find_all(\"a\", href=True)\n",
    "    page_numbers = []\n",
    "\n",
    "    for link in page_links:\n",
    "        text = link.text.strip()\n",
    "        if text.isdigit():\n",
    "            page_numbers.append((int(text), link[\"href\"]))\n",
    "\n",
    "    # Get max page number\n",
    "    max_page = max(num for num, _ in page_numbers)\n",
    "\n",
    "    # Build full URLs for all pages (1 to max_page)\n",
    "    page_urls = [f\"{FILTERED_PAGES_BASE_URL}&page={i}\" if i > 1 else f\"{FILTERED_PAGES_BASE_URL}\" for i in range(1, max_page + 1)]\n",
    "\n",
    "    return page_urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fd717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list homes add link information from page\n",
    "def get_urls_of_home_ads_in_page(page_url):\n",
    "    ad_links = []\n",
    "    soup = create_soup(get_html(page_url))\n",
    "    if  soup:\n",
    "        # Find all home listings\n",
    "        home_cards = soup.find_all(\"div\", class_=\"css-l9drzq\")\n",
    "        for card in home_cards:\n",
    "            link_tag = card.find(\"a\", class_=\"css-1tqlkj0\")\n",
    "            if link_tag:\n",
    "                relative_url = link_tag[\"href\"]\n",
    "                full_url = relative_url if relative_url.startswith(\"http\") else BASE_URL + relative_url\n",
    "                ad_links.append(full_url)\n",
    "    return ad_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e9fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract home information from html content and build Home obects then add them to HomeCollection\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_home_details(soup, home_ad_link=None):\n",
    "    def extract_number(text):\n",
    "    # Remove spaces (used as thousands separators) and any non-digit characters except .\n",
    "        clean_text = text.replace(\" \", \"\").replace(\",\", \".\")\n",
    "        match = re.search(r\"\\d+(\\.\\d+)?\", clean_text)\n",
    "        return float(match.group()) if match else None\n",
    "\n",
    "    # 1. Price\n",
    "    price = None\n",
    "    price_block = soup.find(\"div\", {\"data-testid\": \"ad-price-container\"})\n",
    "    if price_block:\n",
    "        price_text = price_block.get_text(strip=True)\n",
    "        price = extract_number(price_text)\n",
    "\n",
    "    # 2. Address\n",
    "    address = None\n",
    "    address_block = soup.find(\"p\", class_=\"css-7wnksb\")\n",
    "    if address_block:\n",
    "        raw_address = address_block.get_text(strip=True)\n",
    "        # Remove \"Toshkent\" and \"tumani\", clean up commas and spaces\n",
    "        address = raw_address.replace(\"Toshkent\", \"\").replace(\"tumani\", \"\").strip(\", \").strip()\n",
    "\n",
    "\n",
    "    # 3. Parameters block\n",
    "    param_block = soup.find(\"div\", {\"data-testid\": \"ad-parameters-container\"})\n",
    "\n",
    "    data = {\n",
    "        \"number_of_rooms\": None,\n",
    "        \"area\": None,\n",
    "        \"living_area\": None,\n",
    "        \"kitchen_area\": None,\n",
    "        \"floor\": None,\n",
    "        \"total_floors\": None,\n",
    "        \"built_year\": None,\n",
    "        \"bathroom\": None,\n",
    "        \"furnishing_status\": None,\n",
    "        \"status\": \"new\",\n",
    "        \"price\": price,\n",
    "        \"address\": address,\n",
    "        \"with_makler\": False  # default unless detected\n",
    "    }\n",
    "\n",
    "    if not param_block:\n",
    "        return None  # if no structured info, skip\n",
    "\n",
    "    for p in param_block.find_all(\"p\", class_=\"css-1los5bp\"):\n",
    "        text = p.get_text(strip=True)\n",
    "\n",
    "        if \"Xonalar soni\" in text:\n",
    "            data[\"number_of_rooms\"] = int(re.search(r\"\\d+\", text).group())\n",
    "        elif \"Umumiy maydon\" in text:\n",
    "            data[\"area\"] = extract_number(text)\n",
    "        elif \"Yashash maydoni\" in text:\n",
    "            data[\"living_area\"] = extract_number(text)\n",
    "        elif \"Oshxona maydoni\" in text:\n",
    "            data[\"kitchen_area\"] = extract_number(text)\n",
    "        elif \"Qavati\" in text and \"Uy qavatliligi\" not in text:\n",
    "            data[\"floor\"] = int(re.search(r\"\\d+\", text).group())\n",
    "        elif \"Uy qavatliligi\" in text:\n",
    "            data[\"total_floors\"] = int(re.search(r\"\\d+\", text).group())\n",
    "        elif \"Uy qurilgan\" in text:\n",
    "            match = re.search(r\"\\d{4}\", text)\n",
    "            if match:\n",
    "                data[\"built_year\"] = int(match.group())\n",
    "        elif \"Sanuzel\" in text:\n",
    "            data[\"bathroom\"] = \"private\" if \"Alohida\" in text else \"shared\"\n",
    "        elif \"Mebelli\" in text:\n",
    "            data[\"furnishing_status\"] = \"furnished\" if \"Ha\" in text else \"unfurnished\"\n",
    "        elif \"Turarjoy turi\" in text:\n",
    "            data[\"status\"] = \"new\" if \"Yangi\" in text else \"old\"\n",
    "        elif \"Vositachilik haqqi: Bor\" in text:\n",
    "            data[\"with_makler\"] = True\n",
    "        elif \"Vositachilik haqqi: Yoʻq\" in text:\n",
    "            data[\"with_makler\"] = False\n",
    "\n",
    "    # Fallback estimates\n",
    "    if data[\"living_area\"] is None and data[\"area\"] is not None:\n",
    "        data[\"living_area\"] = round(data[\"area\"] * 0.8, 2)\n",
    "    if data[\"kitchen_area\"] is None and data[\"area\"] is not None:\n",
    "        data[\"kitchen_area\"] = round(data[\"area\"] * 0.2, 2)\n",
    "\n",
    "\n",
    "    # Fix swapped values if needed\n",
    "    if (\n",
    "        data[\"floor\"] is not None\n",
    "        and data[\"total_floors\"] is not None\n",
    "        and data[\"floor\"] > data[\"total_floors\"]\n",
    "    ):\n",
    "        data[\"floor\"], data[\"total_floors\"] = data[\"total_floors\"], data[\"floor\"]\n",
    "\n",
    "    try:\n",
    "        home = Home(\n",
    "            price=data[\"price\"],\n",
    "            area=data[\"area\"],\n",
    "            living_area=data[\"living_area\"],\n",
    "            kitchen_area=data[\"kitchen_area\"],\n",
    "            number_of_rooms=data[\"number_of_rooms\"],\n",
    "            status=data[\"status\"],\n",
    "            furnishing_status=data[\"furnishing_status\"],\n",
    "            bathroom=data[\"bathroom\"],\n",
    "            floor=data[\"floor\"],\n",
    "            total_floors=data[\"total_floors\"],\n",
    "            built_year=data[\"built_year\"],\n",
    "            address=data[\"address\"],\n",
    "            with_makler=data[\"with_makler\"],\n",
    "            home_ad_link=home_ad_link\n",
    "        )\n",
    "        return home\n",
    "    except Exception as e:\n",
    "        print(\"❌ Failed to create Home:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84a1fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing page 1/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE\n",
      "processing page 2/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=2\n",
      "processing page 3/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=3\n",
      "processing page 4/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=4\n",
      "processing page 5/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=5\n",
      "processing page 6/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=6\n",
      "processing page 7/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=7\n",
      "processing page 8/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=8\n",
      "processing page 9/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=9\n",
      "Error fetching https://www.olx.uz/d/oz/obyavlenie/muhtasham-sotuvda-3-xonalik-korobka-oloy-bozori-moliya-instituti-ID43foN.html: 504 Server Error: Gateway Time-out for url: https://www.olx.uz/d/oz/obyavlenie/muhtasham-sotuvda-3-xonalik-korobka-oloy-bozori-moliya-instituti-ID43foN.html\n",
      "No HTML content to parse.\n",
      "processing page 10/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=10\n",
      "processing page 11/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=11\n",
      "processing page 12/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=12\n",
      "processing page 13/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=13\n",
      "processing page 14/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=14\n",
      "processing page 15/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=15\n",
      "processing page 16/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=16\n",
      "processing page 17/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=17\n",
      "processing page 18/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=18\n",
      "processing page 19/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=19\n",
      "processing page 20/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=20\n",
      "processing page 21/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=21\n",
      "processing page 22/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=22\n",
      "processing page 23/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=23\n",
      "processing page 24/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=24\n",
      "processing page 25/25: https://www.olx.uz/oz/nedvizhimost/kvartiry/prodazha/q-toshkent-uylar-narxi/?currency=UYE&page=25\n"
     ]
    }
   ],
   "source": [
    "home_collection = HomeCollection()\n",
    "\n",
    "ads_page_urls = get_pages_urls_as_list(get_html(FILTERED_PAGES_BASE_URL))\n",
    "\n",
    "for index, ad_page_url in enumerate(ads_page_urls):\n",
    "    print(f'processing page {index + 1}/{len(ads_page_urls)}: {ad_page_url}')\n",
    "\n",
    "    links_of_ads_in_page = get_urls_of_home_ads_in_page(ad_page_url)\n",
    "\n",
    "    for ad_link in links_of_ads_in_page:\n",
    "        ad_soup = create_soup(get_html(ad_link))\n",
    "        if not ad_soup:\n",
    "            continue  # Skip to the next ad if soup creation failed\n",
    "\n",
    "        home = parse_home_details(ad_soup, home_ad_link=ad_link)\n",
    "        if home:\n",
    "            home_collection.add_home(home)\n",
    "\n",
    "\n",
    "home_df = home_collection.get_all_homes()\n",
    "home_df.to_csv('uzb_housing.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3c9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864547b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
